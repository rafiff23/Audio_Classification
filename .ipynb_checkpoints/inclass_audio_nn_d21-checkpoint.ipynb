{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/logo.png\" width=\"150\">\n",
    "<br>\n",
    "\n",
    "**Coursebook: Processing Audio Data in Python**\n",
    "\n",
    "- Last Update: July 2022\n",
    "___\n",
    "\n",
    "Developed by Kevin Wibowo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coursebook is  prepared by [Algoritma](https://algorit.ma). The coursebook is intended for a restricted audience only, i.e. the individuals and organizations having received this coursebook directly from the training organization. It may not be reproduced, distributed, translated or adapted in any form outside these individuals and organizations without permission.\n",
    "\n",
    "Algoritma is a data science education center based in Jakarta. We organize workshops and training programs to help working professionals and students gain mastery in various data science sub-fields: data visualization, machine learning, data modeling, statistical inference etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preface\n",
    "\n",
    "## Background\n",
    "\n",
    "In this era, types of data are becoming more varied. Demand for processing raw voice data is increasing due to increased demand for sentiment analysis for improving services. This analysis can be used for example at customer services, finding music title, or improving sales through call centers. \n",
    "\n",
    "From these problems we will use audio data for creating machine learning model and one of the most popular and good method for working with unstructured data is using Convolutional Neural Network (CNN).\n",
    "\n",
    "This material aims to provide an understanding for the workshop participants to classify audio data using Convolutional Neural Network (CNN). One Instructor and two Teaching Assistants will help participants troubleshoot or help with any difficulties encountered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Objective\n",
    "\n",
    "\n",
    "- **Python Programming Basics**\n",
    "    - Working with Conda Environment\n",
    "    - Introduction to Python for data science\n",
    "    - Data manipulation and processing with Python Pandas.\n",
    "- **Neural Network Architecture**\n",
    "    - Layer and neurons\n",
    "    - Activation and cost function\n",
    "    - Feedforward\n",
    "    - Backpropagation\n",
    "- **Processing and implementation of classification for Raw Voice data**\n",
    "    - Reading the raw voice data\n",
    "    - Pre-processing Raw Voice data\n",
    "    - Training with validation: define the architecture, compile the model, model fitting and evaluation\n",
    "    - Testing on unseen voices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Programming Basic\n",
    "\n",
    "## Setting up Anaconda Environment\n",
    "\n",
    "**How to create a new virtual environment:**\n",
    "\n",
    "1. Open Anaconda Prompt\n",
    "\n",
    "2. Create new virtual environment with:\n",
    "    ```\n",
    "    conda create -n <ENV_NAME> python=<PYTHON_VERSION>\n",
    "    ```\n",
    "    For example: `conda create -n dss_audio python=3.7`\n",
    "\n",
    "\n",
    "3. Activate the new virtual environment witg:\n",
    "    ```\n",
    "    conda activate <ENV_NAME>\n",
    "    ```\n",
    "    For example: `conda activate dss_audio`\n",
    "    \n",
    "    \n",
    "4. Change your terminal directory to the path where the requirements.txt is located. For example, if your txt file is in the Desktop directory, use: `cd Desktop`\n",
    "\n",
    "\n",
    "5. For standardization packages and libraries installation, please install using the `requirements.txt` shared to you.\n",
    "    ```\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "    \n",
    "6. Install kernel to connect the virtual environment to the Jupyter Notebook.\n",
    "    ```\n",
    "    python -m ipykernel install --user --name=<ENV_NAME>\n",
    "    ```\n",
    "    For example: `python -m ipykernel install --user --name=dss_audio`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Jupyter Notebook\n",
    "\n",
    "### Markdown Cell and Code Cell\n",
    "\n",
    "Kumpulan shortcut: **CTRL + SHIFT + P**\n",
    "\n",
    "Tipe cell dalam notebook:\n",
    "1. Markdown \n",
    "2. Code\n",
    "\n",
    "This is markdown cell. You can write a formatted text such as **bold** or *italic*. You can even write mathematical formula such \n",
    "\n",
    "\\begin{equation}\n",
    "f(x) = \\frac{e^{-x}}{(1+e^{-x})}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command Mode and Edit Mode\n",
    "\n",
    "Mode cell dalam notebook:\n",
    "1. Command mode (cell berwarna BIRU)\n",
    "    - `a` : add cell above \n",
    "    - `b` : add cell below \n",
    "    - `d` + `d` : delete selected cell \n",
    "    - `x` : cut selected cell \n",
    "    - `c` : copy selected cell \n",
    "    - `v` : paste selected cell \n",
    "    - `z` : undo \n",
    "    - `m` : change cell type to markdown \n",
    "    - `y` : change cell type to code\n",
    "    - `enter` : enter Edit Mode\n",
    "    - `h` : show keyboard shortcuts\n",
    "\n",
    "\n",
    "2. Edit mode (cell berwarna HIJAU)\n",
    "    - `Ctrl + Enter`: eksekusi satu cell\n",
    "    - `Shift + enter`: eksekusi satu cell\n",
    "    - `Esc`: Mengubah edit mode menjadi command mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables and Keywords\n",
    "\n",
    "**Variable** adalah sebuah nama yang dipakai untuk menunjukkan sebuah nilai. Tanda `=` dipakai untuk membuat variable baru. Proses ini sering disebut sebagai **assignment**.\n",
    "\n",
    "Python adalah bahasa pemrograman yang **case-sensitive** sehingga penamaan variable menjadi hal yang perlu diperhatikan. Misal penulisan variable `activity` dengan awalan huruf `a` kecil berbeda dengan yang diawali dengan huruf `A` besar.\n",
    "\n",
    "Berikut beberapa anjuran dalam memberikan nama variable pada Python:\n",
    "- Menggunakan kombinasi dari huruf kapital (A-Z), huruf nomina (a-z), angka (0-9).\n",
    "- Special character `!, $ , &, dll` tidak dapat digunakan dalam penamaan variabel. (contoh: you&me) \n",
    "- Tidak boleh menggunakan angka di awal. (contoh: 123Algoritma)\n",
    "- Tidak boleh menggunakan keyword pada Python\n",
    "- Bersifat case-sensitive sehingga penamaan variable `algoritma`, `ALGORITMA`, dan `Algoritma` adalah 3 variable yang berbeda\n",
    "___\n",
    "\n",
    "**Keywords** adalah kata kunci yang sudah ditetapkan oleh Python sebagai nama yang tidak bisa dipakai baik untuk penamaan fungsi, variabel, dan lainnya. Keyword ditulis dalam lower-case (huruf kecil semua) kecuali keyword `True`, `False`, dan `None`. Sejauh ini (Python 3.7) keyword yang ada pada Python adalah sebagai berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kevin'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nama = 'kevin'\n",
    "nama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['False',\n",
       " 'None',\n",
       " 'True',\n",
       " 'and',\n",
       " 'as',\n",
       " 'assert',\n",
       " 'async',\n",
       " 'await',\n",
       " 'break',\n",
       " 'class',\n",
       " 'continue',\n",
       " 'def',\n",
       " 'del',\n",
       " 'elif',\n",
       " 'else',\n",
       " 'except',\n",
       " 'finally',\n",
       " 'for',\n",
       " 'from',\n",
       " 'global',\n",
       " 'if',\n",
       " 'import',\n",
       " 'in',\n",
       " 'is',\n",
       " 'lambda',\n",
       " 'nonlocal',\n",
       " 'not',\n",
       " 'or',\n",
       " 'pass',\n",
       " 'raise',\n",
       " 'return',\n",
       " 'try',\n",
       " 'while',\n",
       " 'with',\n",
       " 'yield']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cek daftar keyword\n",
    "import keyword\n",
    "keyword.kwlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Data Types\n",
    "\n",
    "### String\n",
    "\n",
    "Python mewakili string apa pun sebagai objek `str`. Ada beberapa cara untuk membuat nilai string:\n",
    "\n",
    "- menggunakan `''` (yaitu: `'cyber punk 2077'`)\n",
    "- menggunakan `\"\"` (yaitu : `\"Hari Jum'at\"`)\n",
    "- menggunakan `'''` atau `\"\"\"` (yaitu: `'''Andi berkata \"Jum'at Bersih\"'''`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement = \"nama saya' kevin\"\n",
    "type(statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number\n",
    "\n",
    "Untuk menyimpan number, python memiliki dua tipe data asli yang disebut `int` dan `float`.\n",
    "- `int` digunakan untuk menyimpan bilangan bulat (yaitu: 1,2,-3)\n",
    "- `float` digunakan untuk menyimpan bilangan real (yaitu: 0.7, -1.8, -1000.0).\n",
    "\n",
    "**Operasi Angka** \\\n",
    "Operator Aritmatika:\n",
    "- `+` - Penambahan\n",
    "- `-` - Pengurangan\n",
    "- `*` - Perkalian\n",
    "- `/` - Divisi\n",
    "- `//` - Pembagian Putaran (pembagian dan pembulatan ke bawah)\n",
    "- `%` - Modul (sisa pembagian)\n",
    "- `**` - Eksponen\n",
    "\n",
    "Operator Perbandingan:\n",
    "- `<` - Lebih kecil dari (yaitu : a < b)\n",
    "- `<=` - Lebih kecil atau sama dengan (yaitu : a <= b)\n",
    "- `>` - Lebih besar dari (yaitu: a > b)\n",
    "- `>=` - Lebih besar atau sama dengan (yaitu: a >= b)\n",
    "- `==` - Sama dengan (yaitu: a == b)\n",
    "- `!=` - Tidak Sama dengan (yaitu: a != b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angka = 2*3\n",
    "angka < 7\n",
    "angka == 5 # yang keluar di output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean\n",
    "\n",
    "Boolean menyimpan nilai yang sangat sederhana dalam komputer dan pemrograman, `True` atau `False`.\n",
    "\n",
    "True = 1\n",
    "False = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "print(True + True) # 1 + 1\n",
    "print(False - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structure\n",
    "\n",
    "### List\n",
    "\n",
    "`list` digunakan untuk menyimpan beberapa nilai dalam python. Untuk membuatnya, cukup letakkan nilai di dalam tanda kurung (yaitu: `x = [1,2,3]` )\n",
    "\n",
    "**Operasi List**\n",
    "- `x.append(a)` : tambahkan a ke x\n",
    "- `x.remove(a)` : hapus a dari x\n",
    "\n",
    "Selain operator yang dikenal sebelumnya, salah satu list yang paling berguna adalah dengan menerapkan fungsi agregasi seperti:\n",
    "- `len(x)` : ekstrak panjang daftar\n",
    "- `a in b` : memeriksa apakah nilai `a` ada di objek daftar `b`\n",
    "- `max(x)` : mendapatkan nilai tertinggi dalam x\n",
    "- `sum(x)` : mendapatkan jumlah nilai dalam x\n",
    "\n",
    "Operasi lain yang harus diketahui dalam daftar adalah pengindeksan:\n",
    "- `x[i]` : mengakses elemen ke-i dari x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angka = [2, 3, 4]\n",
    "angka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 7]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angka.append(7)\n",
    "angka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 7]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angka.remove(3)\n",
    "angka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 in angka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(angka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memasukkan nilai ke tengah list\n",
    "angka.insert(1, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 9, 4, 7]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita dapat mengambil nilai di dalam list menggunakan tanda `[]` atau biasa disebut sebagai subsetting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angka[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(angka[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_baru = [1, 'kuda', 19]\n",
    "type(list_baru[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries\n",
    "\n",
    "Kita telah belajar tentang urutan dalam Python tetapi sekarang kita akan beralih dan belajar tentang mapping pada Python. Jika Anda terbiasa dengan bahasa lain, Anda dapat menganggap Dictionaries ini sebagai tabel hash.\n",
    "\n",
    "Python dictionary terdiri dari **key** dan kemudian **value** terkait. Nilai itu bisa berupa hampir semua objek Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary with {} and : to signify a key and a value\n",
    "profil = {'nama': 'kevin', # key1 : value1\n",
    "         'pekerjaan': 'instructor'} # key2 : value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary with {} and : to signify a key and a value\n",
    "profil2 = {'nama': ['kevin', 'fafilia'], # key1 : value1\n",
    "         'pekerjaan': ['instructor', 'TA']} # key2 : value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instructor', 'TA']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call values by their key\n",
    "profil2['pekerjaan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sama seperti list, satu dictionary mampu menyimpan tipe data yang berbeda. Sebagai contoh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "profil2 = {'nama': ['kevin', 'fafilia'], \n",
    "         'pekerjaan': ['instructor', 'TA'],\n",
    "          'umur': [20, 19]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call items from the dictionary\n",
    "profil2['umur'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function\n",
    "\n",
    "Function merupakan sekelompok perintah yang digunakan untuk melakukan tugas tertentu. Ketika kita melakukan sesuatu yang berulang dan rumit, alangkah baiknya kita menggunakan fungsi agar tidak ada langkah yang berubah maupun penulisan kode yang salah. Penulisan umum sebuah fungsi yaitu:\n",
    "```\n",
    "def nama_fungsi(parameter):\n",
    "    perintah\n",
    "```\n",
    "Pada syntax umum di atas, `def` merupakan inisiator untuk sebuah fungsi. Sementara hal-hal yang harus kita tentukan yaitu nama dari fungsi, parameter yang akan digunakan di dalamnya, serta perintah atau kode. \n",
    "\n",
    "Sebagai contoh, kita akan membuat sebuah fungsi penjumlahan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def halo():\n",
    "    print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "halo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tambah(angka_1, angka_2):\n",
    "    hasil = angka_1 + angka_2\n",
    "    print(hasil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "tambah(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada fungsi tersebut kita mencetak hasil perhitungan menggunakan fungsi `print()`, tetapi nilainya tidak bisa kita simpan. \n",
    "Sebagai contoh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "total = tambah(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk melakukan penyimpanan nilai, kita harus menggunakan perintah `return` dari nilai yang ingin kita simpan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tambah2(angka_1, angka_2):\n",
    "    hasil = angka_1 + angka_2\n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = tambah2(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter bisa didefinisikan nilai defaultnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tambah3(angka_1=1, angka_2=2):\n",
    "    hasil = angka_1 + angka_2\n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tambah3(angka_1=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Array\n",
    "\n",
    "Numpy adalah library utama untuk scientific computing menggunakan Python. Library ini menyediakan objek multidimensional array  dan berbagai function yang dapat dimanfaatkan untuk array tersebut.\n",
    "\n",
    "**Numpy array** adalah kumpulan nilai, yang memiliki tipe data yang sama, dan diindeks oleh tuple bilangan bulat non-negatif. \n",
    "Jumlah dimensi adalah deretan array; bentuk array adalah tuple bilangan bulat yang menunjukkan ukuran array pada setiap dimensi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3,)\n",
      "1 2 3\n",
      "[5 2 3]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])   # Create a rank 1 array\n",
    "\n",
    "print(type(a))            # Prints \"<class 'numpy.ndarray'>\"\n",
    "print(a.shape)            # Prints \"(3,)\"\n",
    "print(a[0], a[1], a[2])   # Prints \"1 2 3\"\n",
    "a[0] = 5                  # Change an element of the array\n",
    "print(a)                  # Prints \"[5, 2, 3]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "1 2 4\n"
     ]
    }
   ],
   "source": [
    "b = np.array([[1,2,3],[4,5,6]])    # Create a rank 2 array\n",
    "print(b.shape)                     # Prints \"(2, 3)\"\n",
    "print(b[0, 0], b[0, 1], b[1, 0])   # Prints \"1 2 4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array() # method\n",
    "# b.shape # atribut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîé **Method vs. Atribut**\n",
    "\n",
    "- Secara fisik/kasat mata, method selalu diikuti dengan tanda kurung ()\n",
    "- Secara fisik/kasat mata, atribut tidak diikuti oleh tanda kurung\n",
    "- Didalam sebuah method, nilai parameter bisa diganti-ganti\n",
    "- Pada sebuah atribut, penggunaaan apa adanya/tidak ada nilai yang bisa diganti ganti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "**Neural network** atau artificial neural network (ANN) adalah metode machine learning yang *terinspirasi dari cara kerja otak manusia* mengirimkan informasi melalui sistem saraf (biological neural network). Terdapat 2 hal utama dari neural network: **arsitektur** & **learning process** yang dilakukan.\n",
    "\n",
    "## Arsitektur Neural Network\n",
    "\n",
    "Sistem saraf yang dimiliki manusia terdiri dari sel saraf yang dinamakan **neuron**, dan neuron tersebut amat banyak hingga membentuk **jaringan**. Tiap stimulus/input dari luar akan diterima oleh panca indra sebagai signal kemudian akan dialirkan melalui satu sel saraf ke sel saraf lainnya. Jaringan sel saraf tersebar dari ujung jari hingga otak dan berlanjut kembali ke seluruh tubuh kita. \n",
    "    \n",
    "> Jaringan sel saraf mengalirkan informasi dari area stimulus/**input**, diproses melalui otak, lalu dikembalikan kepada tubuh sebagai **output** atau respon yang kita berikan.\n",
    "\n",
    "Human Neuron  |  Artificial Neural Network's Neuron\n",
    "-- | --\n",
    "![neuron](assets/bnn.png) | ![neuron](assets/ann.PNG)\n",
    "\n",
    "Arsitektur sistem saraf inilah yang menginspirasi terbentuknya model neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding How Neural Network Works\n",
    "\n",
    "Untuk mengetahui lebih jelas kita akan coba bahas melalui grafik berikut:\n",
    "\n",
    "![nn works](assets/nn_works.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![neuron](assets/ann.PNG)\n",
    "üí° Pada model neural network, informasi dialirkan dan diproses melalui arsitektur yang terdiri dari:\n",
    "\n",
    "* **neuron/node**: tempat informasi disimpan\n",
    "* **input layer**: layer yang menerima input sekaligus layer pertama; node sejumlah variable input/prediktor (x1, x2, ..., xn)\n",
    "* **hidden layer**: layer antara input & output, tempat *proses informasi*; jumlah layernya bisa lebih dari 1, yang menentukan adalah user\n",
    "* **output layer**: layer yang mengeluarkan output (hasil prediksi) sekaligus layer terakhir; node sejumlah variabel target (y)\n",
    "- _**weight**_: informasi yang dibawa oleh setiap neuron. Awalnya bobot ini akan di inisialisasi secara random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outline bahasan day 1\n",
    "\n",
    "1. Virtual environment -> dss_audio\n",
    "2. Fitur-fitur jupyter notebook\n",
    "3. Basic python:\n",
    "    - variable & keywords\n",
    "    - tipe data (string, number, boolean)\n",
    "    - struktur data (list, dict)\n",
    "    - function\n",
    "    - numpy array\n",
    "4. Neural network\n",
    "    - konsep dasar\n",
    "    - arsitektur\n",
    "    - learning process\n",
    "\n",
    "END OF DAY 1\n",
    "___\n",
    "\n",
    "START OF DAY 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Neuron with Keras \n",
    "\n",
    "Untuk lebih memahami tentang cara kerja neuron, coba kita buat suatu model yang terdisi dari satu neuron menggunakan `Keras`.\n",
    "\n",
    "Contoh kita buat dummy data yang terdiri dari `x` sebagai prediktor dan `y` sebagai target variabel. Tugas kita akan membuat model yang memprediksi nilai `y` berdasarkan nilai pada data `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Tensorflow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create quick example of x and y data\n",
    "x_train = np.array([1,2,3,4,5,10]) # Predictor\n",
    "y_train = np.array([3,5,7,9,11,21]) # Target Variable\n",
    "\n",
    "x_test = np.array([16, 17, 18, 19, 20, 100, 200])\n",
    "y_test = np.array([33, 35, 37, 39, 41, 201, 401])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Model Initialization** \\\n",
    "Langkah pertama dalam membuat model adalah dengan menginisialisasinya. Dalam keras, kita dapat menggunakan metode `keras.Sequential()` untuk membuat objek model sequential\n",
    "\n",
    "- Documentation: https://keras.io/guides/sequential_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set randomness so the model is reproducible\n",
    "import random\n",
    "random.seed(722)\n",
    "np.random.seed(722)\n",
    "tf.random.set_seed(722)\n",
    "\n",
    "# Model Initialization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏èTambahkan layer pada model yang sudah kita buat dengan menggunakan method `add()`\n",
    "\n",
    "input_shape = merujuk pada jumlah nodes (jumlah kolomnya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop model blueprints \n",
    "\n",
    "\n",
    "# Model Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Model Compilation**\n",
    "\n",
    "Setelah desain model dibuat, selanjutnya harus dikompilasi dengan **loss function** (cost function) yang benar dan **optimizer** untuk mengukur kinerjanya selama proses training. Jika Anda tidak begitu memahami cara kerja optimizer, jangan khawatir karena kita akan membahasnya nanti dalam kursus ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Compilation\n",
    "model.compile(optimizer='SGD', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut ilustrasi model yang telah kita buat di sel sebelumnya\n",
    "\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah kita membuat model, kita mungkin ingin tahu tentang nilai masing-masing bobot (`w` dan `b`). Secara default, keras akan mengacak nilai menggunakan [glorot normal distributions](https://keras.io/api/layers/initializers/). Untuk melihat bobot dapat memanggil kode yang disajikan di bawah ini dan kita akan melihat setiap kali kita menginisialisasi model, bobotnya akan berubah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Model Train**\n",
    "\n",
    "Proses training dalam arsitektur neural network sedikit berbeda dari model lainnya. Proses ini terdiri dari dua langkah yaitu:\n",
    "\n",
    "1. **Feedforward** : Proses untuk mengirimkan data ke dalam model dan menghasilkan output (dalam hal ini, prediksi y atau biasanya dilambangkan dengan $\\hat{y}$)\n",
    "2. **Backpropagation** : Proses untuk mengevaluasi error/loss antara $\\hat{y}$ dan $y$, kemudian memperbarui model untuk meningkatkan kinerjanya nanti\n",
    "\n",
    "Seluruh proses feedforward dan backpropagation dilakukan saat kita memanggil fungsi `.fit()` di bawah ini:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah pelatihan Anda selesai, Anda akan melihat bobot model harusnya mendekati rumus $2x + 1$ (angka ini didapatkan dengan menghitung x dan y yang digunakan pada data train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Model Evaluation**\n",
    "\n",
    "Dalam contoh sebelumnya kita dapat mengukur kinerja model pada seberapa dekat untuk membuat rumus $2x+1$. Namun pada kenyataannya, kita bahkan tidak tahu rumus untuk data tersebut. Oleh karena itu, kita biasanya mengandalkan kinerja pengujian model. Sama seperti kasus machine learning, kita dapat memanfaatkan data training kemudian membandingkan kinerja training dan kinerja testing untuk membuat kesimpulan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the model to predict y out of x\n",
    "model.predict([___])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Knowledge Check\n",
    "\n",
    "1. Manakah dibawah ini yang **tidak** bisa diselesaikan dengan Neural Network?\n",
    "\n",
    "    - [ ] a. Masalah Regresi\n",
    "    - [ ] b. Masalah Klasifikasi\n",
    "    - [ ] c. Masalah Clustering\n",
    "    - [ ] d. Masalah Hardware\n",
    "\n",
    "2. Berapa banyak output layer yang diperlukan untuk membangun Artificial Neural Network?\n",
    "    - [ ] a. 1\n",
    "    - [ ] b. 2\n",
    "    - [ ] c. 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/layer_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Manakah pernyataan yang benar?\n",
    "\n",
    "    - [ ] a. Input layer: 1, Output layer: 3, Hidden layer: 3\n",
    "    - [ ] b. Input layer: 1, Output layer: 1, Hidden layer: 2\n",
    "    - [ ] c. Input layer: 3, Output layer: 3, Hidden layer: 2\n",
    "\n",
    "\n",
    "4. Gambar diatas apabila kita implementasikan pada keras menjadi seperti berikut:\n",
    "\n",
    "```\n",
    "model_dummy = keras.Sequential()\n",
    "model_dummy.add(keras.layers.InputLayer(input_shape=[__A__]))\n",
    "model_dummy.add(keras.layers.Dense(units=__B__))\n",
    "model_dummy.add(keras.layers.Dense(units=__C__))\n",
    "model_dummy.add(keras.layers.Dense(units=__D__))\n",
    "```\n",
    "\n",
    "   - [ ] a. A: 3, B: 5, C: 5, D: 4\n",
    "   - [ ] b. A: 1, B: 4, C: 4, D: 1\n",
    "   - [ ] c. A: 3, B: 4, C: 4, D: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/skema_sum.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Apa nama yang tepat untuk mengidentifikasi nomor diatas\n",
    "    + 1: ____\n",
    "    + 2,3,4: ____ \n",
    "    + 5: ____\n",
    "    + 7: ____\n",
    "    + 8: ____\n",
    "    \n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron\n",
    "\n",
    "Sesuai dengan namanya, arsitektur artificial neural network adalah kumpulan neuron yang saling terhubung dan terdiri dari 3 jenis lapisan :\n",
    "1. Input Layer\n",
    "2. Hidden Layer\n",
    "3. Output Layer\n",
    "\n",
    "Karena arsitekturnya terbentuk dari beberapa lapisan perceptron, beberapa menyebutnya multi-layer perceptron (MLP). Istilah asli deep learning muncul ketika neural network memiliki banyak hidden layer yang membentuk lapisan yang \"deep\". Di bawah ini adalah referensi untuk perbedaan kedua arsitektur tersebut.\n",
    "\n",
    "![image](https://drive.google.com/uc?export=view&id=1QPPMzjirFkxylcWT-HzBfTyC4sJiK_R5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Audio Data\n",
    "\n",
    "Audio merupakan bentuk gelombang yang menghasilkan suara. Suara pada manusia dihasilkan dari getaran vocal cord (pita suara) yang terdapat pada pangkal tenggorokan pada jakun. Ketika kedua pita bersatu dan terdapat udara hasil ekspirasi dari paru-paru yang melewatinya, maka akan timbul getaran yang menghasilkan bunyi. Suara juga dapat dihasilkan oleh benda-benda mati berdasarkan konsep yang sama dengan manusia, yaitu getaran. Getaran suara menentukan osilasi molekul udara yang menciptakan pergantian tekanan udara dan menyebabkan gelombang. \n",
    "\n",
    "Gelombang/getaran suara yang merambat melalui udara ini dapat direkam secara digital dan inilah salah satu bentuk unstructured data yang kita kenal. Gelombang suara memiliki berbagai atribut yang menentukan tinggi rendahnya nada, kecil besarnya volume suara, dsb. Contoh dari atribut tersebut adalah frekuensi, amplitudo, dan panjang gelombang (lambda). Informasi pada data audio tersimpan pada atribut-atribut tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Shape of Audio Data\n",
    "\n",
    "Untuk membaca data audio pada python kita membutuhkan library tambahan yaitu **librosa**. Ekstraksi data menggunakan librosa akan menghasilkan data dengan bentuk gelombang (waveform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # library untuk pengolahan data angka\n",
    "import matplotlib.pyplot as plt # library dasar visualisasi \n",
    "import librosa # library khusus analisa data audio\n",
    "import librosa.display # library visualisasi data audio, dibangun dari matplotlib\n",
    "import IPython.display as ipd # library to show audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahapan pertama yang harus dilakukan yaitu membaca file audio. Untuk melakukan hal ini kita akan menggunakan fungsi `.load()` dari library librosa. Fungsi ini membutuhkan dua buah parameter utama yaitu:\n",
    "- path: lokasi penempatan file\n",
    "\n",
    "Selain membaca data audio, fungsi ini juga mengeluarkan nilai sample rate. Sample rate ini merupakan jumlah sampel audio per detik (frekuensi) dan nilai default yang dipakai yaitu 22050 (jumlah frekuensi yang masih bisa didengar oleh manusia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data_input/genres_train/blues/blues.00050.wav\"\n",
    "\n",
    "signal, sample_rate = \n",
    "ipd.Audio(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(signal)\n",
    "print(sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari variabel `signal` di atas, kita dapat melihat bahwa data hasil ekstraksi merupakan angka-angka yang berurutan. Untuk melihat bentuk datanya, kita akan menggunakan visualisasi menggunakan fungsi `waveplot()` dari package `librosa.display`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "librosa.display.waveplot(y=signal, sr=sample_rate, alpha=0.3)\n",
    "plt.xlabel(\"Waktu (detik)\")\n",
    "plt.ylabel(\"Amplitudo\")\n",
    "plt.title(\"Gelombang Suara\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari ekstraksi data audio di atas, kita belum bisa mendapatkan banyak informasi. Beberapa hal yang bisa kita tangkap dapat dilihat Oleh karena itu langkah berikutnya adalah mengubah bentuk datanya dari domain waktu ke domain frekuensi menggunakan perhitungan Fast Fourier Transform (FFT). Sederhananya, apa yang dilakukan FFT ditunjukkan pada gambar berikut:\n",
    "\n",
    "![fft](assets/fft.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghitung nilai fft\n",
    "fft = np.fft.fft(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jika kita inspeksi nilai hasil FFT maka yang didapatkan adalah bilangan kompleks, oleh karena itu perlu diubah agar dapat dibaca sebagai magnitude/power. Pengubahan yang dilakukan adalah dengan menghitung nilai absolut-nya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghitung nilai hasil fft untuk mendapatkan magnitudo\n",
    "spectrum = np.abs(fft)\n",
    "\n",
    "# membuat bin untuk frekuensi\n",
    "freq = np.linspace(0, sample_rate, len(spectrum))\n",
    "\n",
    "# plot visualisasi\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(freq, spectrum, alpha=0.3)\n",
    "plt.xlabel(\"Frekuensi\")\n",
    "plt.ylabel(\"Magnitudo\")\n",
    "plt.title(\"Power spectrum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil visualisasi yang dapat simetrikal, dengan titik potong pada jumlah total data `spectrum` dibagi 2. Untuk membuang informasi yang redundant ini, kita cukup mengambil setengah bagian awal. Hal ini dapat dilakukan dengan langkah berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_spectrum = spectrum[:int(len(spectrum)/2)]\n",
    "left_freq = freq[:int(len(spectrum)/2)]\n",
    "\n",
    "# plot spectrum\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(left_freq, left_spectrum, alpha=0.4)\n",
    "plt.xlabel(\"Frekuensi\")\n",
    "plt.ylabel(\"Magnitudo\")\n",
    "plt.title(\"Power spectrum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil yang kita lihat di atas adalah gelombang suara yang ditunjukkan dengan domain frekuensi. Informasi tersebut merangkum keseluruhan informasi yang terdapat pada data kita atau dapat dikatakan data di atas adalah sebuah snapshot yang menangkap semua frekuensi selama keseluruhan waktu dari data audio kita. \n",
    "Padahal pada setiap langkah waktu di data audio berubah-ubah sehingga kita ingin mempertahankan hal ini, oleh karena itu kita akan menggunakan Short-time Fourier Transform (STFT). STFT adalah proses FFT normal tetapi dilakukan bersegmen sehingga informasi waktu tetap ada. \n",
    "\n",
    "Pada STFT terdapat 2 argument/parameter baru yang harus kita definisikan yaitu `hop_length` dan `n_fft`, keduanya berhubungan dengan jarak setiap fft serta jumlah data per fft. Berikut penggambaran yang menjelaskan keduanya:\n",
    "![hop-nfft](assets/nfft-hoplength.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STFT -> spectrogram\n",
    "hop_length = 512 # hop of each fft\n",
    "n_fft = 2048 # total sample per fft window\n",
    "\n",
    "# perform stft\n",
    "stft = librosa.stft(y=signal, n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "# calculate absolute values on complex numbers to get magnitude\n",
    "spectrogram = np.abs(stft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisasi untuk STFT ini ditampilkan dalam bentuk spectrogram, sebuah diagram untuk menampilkan suatu gelombang dalam jangka waktu yang pendek. Fungsi yang dapat digunakan yaitu `specshow()` dari librosa.display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display spectrogram\n",
    "plt.figure(figsize=(14,6))\n",
    "librosa.display.specshow(spectrogram, sr=sample_rate, hop_length=hop_length, y_axis = 'fft', x_axis = 'time')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Spectrogram (amplitudo)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply logarithm to convert amplitude to Decibels\n",
    "log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
    "\n",
    "# display spectrogram\n",
    "plt.figure(figsize=(14,6))\n",
    "librosa.display.specshow(log_spectrogram, sr=sample_rate, hop_length=hop_length, y_axis = 'fft', x_axis = 'time')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Spectrogram (dB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita mempelajari keseluruhan proses di atas karena kita akan menggunakan Mel Frequency Cepstral Coefficients (MFCC). MFCC adalah sebuah metode untuk meng-ekstraksi fitur suara menjadi angka, koefisien ini juga memperhitungkan kualitas suara seperti manusia mempersepsikan suara. \n",
    "Untuk mendapatkan nilai MFCC kita akan menggunakan fungsi `mfcc()` dari `librosa.feature` dengan argument yang digunakan yaitu:\n",
    "- `signal`: didapat dari hasil ekstraksi awal, \n",
    "- `sample_rate`: sample data per detik, \n",
    "- `n_fft`: jumlah data per window FFT,\n",
    "- `hop_length`: jarak lompatan setiap FFT,\n",
    "- `n_mfcc`: jumlah koefisien MFCC yang ingin diekstrak (normalnya 13, tetapi bisa mencapai 40).\n",
    " \n",
    "Seluruh argument yang digunakan merupakan bagian dari yang sudah dipelajari sebelumnya. Penjelasan lengkap tentang MFCC dapat kita lihat di [link berikut](https://link.springer.com/content/pdf/bbm%3A978-3-319-03116-3%2F1.pdf) dan proses lengkapnya ditampilkan pada bagan di bawah ini:\n",
    "\n",
    "![mfcc](assets/MFCC.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCCs\n",
    "# extract 13 MFCCs\n",
    "MFCCs = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display MFCCs\n",
    "plt.figure(figsize=(14,6))\n",
    "librosa.display.specshow(MFCCs, sr=sample_rate, hop_length=hop_length, x_axis = 'time')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"MFCC coefficients\")\n",
    "plt.colorbar()\n",
    "plt.title(\"MFCCs\")\n",
    "\n",
    "# show plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other features**\n",
    "\n",
    "Selain menggunakan MFCC, masih banyak cara lain untuk mendapatkan informasi data audio. Tentunya cara-cara tersebut memiliki berbagai teknik yang berbeda sehingga dapat berpengaruh pada pencarian pola ketika membuat model. Berikut ini adalah beberapa contohnya:\n",
    "- Zero Crossing Rate,\n",
    "- Spectral Centroid,\n",
    "- Energy,\n",
    "- Chroma Vector,\n",
    "dan masih banyak lagi. \n",
    "\n",
    "Beberapa sumber terkait feature extraction ini dapat dibaca lebih lanjut pada:\n",
    "- [Audio signal feature extraction and clustering - Medium](https://medium.com/heuristics/audio-signal-feature-extraction-and-clustering-935319d2225)\n",
    "- [Get to Know Audio Feature Extraction in Python - Toward Data Science](https://towardsdatascience.com/get-to-know-audio-feature-extraction-in-python-a499fdaefe42)\n",
    "- [Music Feature Extraction in Python - Toward Data Science](https://towardsdatascience.com/extract-features-of-music-75a3f9bc265d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Implementing Neural Network for Audio Classification\n",
    "\n",
    "Pada bagian sebelumnya kita sudah mengimplementasikan neural network untuk kasus linier. Pada bagian ini kita akan mencoba menggunakan neural network untuk dataset audio. Langkah-langkah yang akan kita jalani yaitu:\n",
    "1. Data preparation\n",
    "2. Making architecture\n",
    "3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "Nilai dari koefisien MFCC di atas akan digunakan sebagai fitur, oleh karena itu kita perlu mempersiapkan fungsi untuk melakukan konversi keseluruhan data yang kita punya menjadi data koefisien MFCC. Berikut ini adalah fungsi yang sudah dipersiapkan untuk hal tersebut. Tahapan yang akan dilakukan oleh fungsi `save_mfcc()` ini yaitu:\n",
    "- Mengakses folder tempat data disimpan\n",
    "- Membaca data satu per satu\n",
    "- Load setiap data\n",
    "- Melakukan segmentasi data untuk kebutuhan data augmentasi\n",
    "- Menyimpan nilai ke dictionary\n",
    "- Menyimpan dictionary ke format .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n",
    "    \"\"\"Extracts MFCCs from music dataset and saves them into a json file along witgh genre labels.\n",
    "    \n",
    "    --Arguments--\n",
    "        dataset_path: str \n",
    "            Path to dataset\n",
    "        json_path: str \n",
    "            Path to json file used to save MFCCs\n",
    "        num_mfcc: int \n",
    "            Number of coefficients to extract\n",
    "        n_fft: int\n",
    "            Interval we consider to apply FFT. Measured in # of samples\n",
    "        hop_length: int\n",
    "            Sliding window for FFT. Measured in # of samples\n",
    "        num_segments: int \n",
    "            Number of segments we want to divide sample tracks into\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # dictionary to store mapping, labels, and MFCCs\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "    }\n",
    "    \n",
    "    # constant for making segmentation when extracting mfcc\n",
    "    samples_per_segment = int(samples_per_file / num_segments)\n",
    "    # constant for shape checking after extracting mfcc\n",
    "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "\n",
    "    # loop through all label sub-folder\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "\n",
    "        # ensure we're processing a label sub-folder level\n",
    "        if dirpath is not dataset_path:\n",
    "\n",
    "            # save label (i.e., sub-folder name) in the mapping\n",
    "            semantic_label = os.path.split(dirpath)[-1]\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
    "\n",
    "            # process all audio files in each label sub-dir\n",
    "            for f in filenames:\n",
    "\n",
    "                # load audio file\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                signal, sample_rate = librosa.load(file_path, sr=sr)\n",
    "\n",
    "                # process all segments of audio file\n",
    "                for d in range(num_segments):\n",
    "\n",
    "                    # calculate start and finish sample for current segment\n",
    "                    start = samples_per_segment * d\n",
    "                    finish = start + samples_per_segment\n",
    "\n",
    "                    # extract mfcc per segments (data augmentation)\n",
    "                    mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, \n",
    "                                                n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "                    mfcc = mfcc.T\n",
    "\n",
    "                    # store only mfcc feature with expected number of vectors (to make each of our data have same shape)\n",
    "                    if len(mfcc) == num_mfcc_vectors_per_segment:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(i-1)\n",
    "\n",
    "    # save MFCCs to json file\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset_path = \"data_input/genres_train\"\n",
    "# json_path = \"data.json\"\n",
    "# sr = 22050 # default sample rate\n",
    "# file_duration = 30 # measured in seconds\n",
    "# samples_per_file = sr * file_duration # total data which need to be converted per file\n",
    "\n",
    "# save_mfcc(dataset_path, json_path, num_segments=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperti yang sudah dibahas sebelumnya, pada course ini kita akan mencoba membuat klasifikasi genre lagu menggunakan neural network, dengan data yang digunakan yaitu koefisien MFCC yang sudah diekstraksi. Karena data yang kita akan gunakan sudah dikonversi ke bentuk `.json` maka kita akan membuat sebuah fungsi untuk membaca data kita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def load_data(data_path):\n",
    "    \"\"\"Loads training dataset from json file.\n",
    "        :param data_path (str): Path to json file containing data\n",
    "        :return X (ndarray): Inputs\n",
    "        :return y (ndarray): Targets\n",
    "    \"\"\"\n",
    "\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    # convert lists to numpy arrays\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    print(\"Data succesfully loaded!\")\n",
    "\n",
    "    return  X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah itu seperti proses umum pembuatan model machine learning, kita akan pisahkan datanya menjadi data training dan data testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load data\n",
    "X, y = load_data(\"data.json\")\n",
    "\n",
    "# create train/test split\n",
    "\n",
    "\n",
    "# Check type and shape\n",
    "print('data type \\t: ', type(X_train), type(y_train))\n",
    "print('training size \\t: ', X_train.shape, y_train.shape)\n",
    "print('Test size \\t: ', X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Process in Neural Network\n",
    "\n",
    "Neural Network bekerja dengan mengevaluasi error dan mengupdate nilai bobot/weight. 1 Proses mengevaluasi dan mengupdate bobot disebut dengan 1 step/epoch. 1 step terdiri dari 2 fase:\n",
    "\n",
    "* **Feed Forward** : Memprediksi nilai target (y)\n",
    "* **Back Propagation** : Mengupdate nilai bobot berdasarkan nilai error yang didapatkan\n",
    "\n",
    "![nn works](assets/nn_works.png)\n",
    "\n",
    "1. Membuat weight dan bias secara random\n",
    "\n",
    "Ulangi langkah berikut hingga mencapai konvergen (tidak mengalami penurunan error yang signifikan) atau batas yang ditentukan (jumlah step):\n",
    "\n",
    "2. Feed Forward : Memprediksi nilai target y sesuai dengan bobot yang dimiliki sekarang\n",
    "\n",
    "3. Menghitung nilai error\n",
    "\n",
    "4. Back Propagation : Mencari perubahan bobot yang memberikan error minimum\n",
    "\n",
    "5. Update Bobot sesuai hasil Back Propagation\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward\n",
    "\n",
    "Feed forward adalah proses model memprediksi nilai target berdasarkan bobot dan bias yang dimiliki. Pada ilustrasi berikut, model akan menerima input dari setiap prediktor/feature yang kemudian akan diolah sesuai dengan bobot dari masing-masing neuron/node ditambah dengan nilai biasnya. \n",
    "\n",
    "- Tanda `S` pada hidden layer dan output layer menunjukkan bahwa terjadi perubahan skala data menjadi 0-1 karena kita menggunakan activation function berupa `Sigmoid Function`.\n",
    "\n",
    "![feed forward](assets/forward.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "\n",
    "**Activation Function** berfungsi untuk mentransformasi input sebelum diteruskan ke layer selanjutnya sesuai dengan kebutuhan. Istilah activation function terinspirasi dari cara otak bekerja dengan mengaktifkan atau menonaktifkan sel syaraf. Hal ini bermanfaat agar:\n",
    "\n",
    "* nilai yang diteruskan sudah dalam bentuk sepatutnya (misal output klasifikasi berupa peluang: 0~1)\n",
    "* menjaga agar nilai yang diteruskan ke node-node selanjutnya tidak semakin besar dan memperberat komputasi.\n",
    "\n",
    "üí° Beberapa jenis activation function:\n",
    "\n",
    "- Linier\n",
    "    + jenis default perhitungan linier \n",
    "    \n",
    "- Tanh\n",
    "    + (Hyperbolic tangent) : digunakan pada hidden layer\n",
    "    + Alternatif untuk sigmoid. Skala output yang dihasilkan adalah -1 hingga 1 (zero centered).\n",
    "\n",
    "- Rectified Linear unit (ReLU)\n",
    "    + Biasa digunakan di hidden layer. bagus untuk kasus image (range 0 ~ inf)\n",
    "    + Jika nilai inputnya kurang dari 0 (negatif), maka diubah menjadi 0.\n",
    "\n",
    "- Logistic (sigmoid)\n",
    "    + Cocok di output dan untuk kasus klasifikasi (biner) (range 0 ~ 1).\n",
    "    + Mengkonversi nilai numerik menjadi skala 0-1, sehingga cocok untuk klasifikasi 2 kelas.  \n",
    "\n",
    "- Softmax\n",
    "    + Biasa digunakan di output layer untuk kasus klasifikasi (multiclass) (range 0 ~ 1)\n",
    "    + Sama seperti dengan sigmoid, hanya saja dapat menerima lebih dari 2 kelas (multiclass). Softmax akan memastikan bahwa output dari sebuah vektor adalah distribusi peluang yang jika ditotal semuanya adalah 1. Misalkan untuk klasifikasi dengan 3 kelas (high, low, normal) maka peluang dari masing-masing kelas saat ditotal adalah 1.\n",
    "\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1KAcL458IRdWsMYfTSZRA6K61zAhrAeY9\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîé Knowledge Check Activation Function\n",
    "\n",
    "- ‚ùìApa activation function yang cocok untuk kasus regresi dengan target variabel numerik?\n",
    "\n",
    "> `activation_function='____'`\n",
    "\n",
    "- ‚ùìApa activation function yang cocok untuk kasus klasifikasi dengan target variabel adalah kategori dengan 5 kelas?\n",
    "\n",
    "> `activation_function='____'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function / Cost Function (Error)\n",
    "\n",
    "Loss function digunakan untuk pedoman belajar dari model Neural Network. Loss function untuk setiap jenis permasalahan bisa berbeda-beda. Dokumentasi dapat dilihat pada: https://keras.io/api/losses/\n",
    "\n",
    "Memilih Loss Function yang tepat untuk problem yang tepat sangatlah penting: Neural Network akan mengambil jalan pintas apa pun yang dapat dilakukan untuk meminimalkan kerugian. Loss function, yang dapat digunakan untuk mengestimasi kerugian model sehingga bobot dapat diperbarui untuk mengurangi kerugian pada evaluasi berikutnya.\n",
    "\n",
    "* Regresi\n",
    "\n",
    "    + Pada kasus regresi (target variabel numerik), loss yang biasa digunakan adalah:\n",
    "        - **MSE atau Mean Squared Error**. \n",
    "            + Seperti namanya, kerugian ini dihitung dengan mengambil rata-rata perbedaan kuadrat antara nilai aktual (target) dan prediksi. Pengkuadratan berarti bahwa kesalahan yang lebih besar menghasilkan lebih banyak kesalahan daripada kesalahan yang lebih kecil, artinya model dihukum karena membuat kesalahan yang lebih besar.\n",
    "            + Setting parameter: `<model>.compile(loss='mean_squared_error')`\n",
    "        - **MSLE atau Mean Squared Logarithmic Error**\n",
    "            + Kerugian ini akan melonggarkan efek hukuman dari berbedaan nilai yang signifikan dari prediksi.  \n",
    "            + Setting parameter: `<model>.compile(loss='mean_squared_logarithmic_error')`\n",
    "\n",
    "        - **MAE atau Mean Absolute Error**\n",
    "            + Kerugian ini dihitung sebagai rata-rata perbedaan absolut antara nilai aktual dan prediksi. Cocok digunakan untuk data yang memiliki banyak outlier. \n",
    "            + Setting parameter: `<model>.compile(loss='mean_absolute_error')`\n",
    "\n",
    "* Klasifikasi\n",
    "\n",
    "    + Untuk kasus klasifikasi dengan target diskrit berupa kategorikal, loss yang biasa digunakan adalah:\n",
    "        - **Binary Cross Entropy**. \n",
    "            + Cross-entropy adalah fungsi loss default yang digunakan untuk masalah klasifikasi biner atau 2 kelas target. Biner di mana nilai target berada di set {0, 1}\n",
    "            + BCE akan menjumlahkan nilai selisih probability rata-rata antara aktual dengan prediksi untuk memprediksi kelas target 1. \n",
    "            + Setting parameter: `<model>.compile(loss='binary_crossentropy')`\n",
    "        - **Sparse Categorical Cross Entropy**. \n",
    "            + Digunakan untuk klasifikasi multi-kelas, dimana nilai targetnya akan diberi label {0,1,2,3,...,n}\n",
    "            + SCCE akan menjumlahkan nilai selisih probability rata-rata antara aktual dengan prediksi dalam memprediksi semua kelas target.\n",
    "            + Setting parameter: `<model>.compile(loss='sparse_categorical_crossentropy')` , dengan syarat jumlah node output sama dengan jumlah kelas\n",
    "        - **Categorical Cross Entropy**. \n",
    "            + Tujuan dan cara perhitungannya sama seperti SCCE namum dalam praktik penggunaannya target yang digunakan perlu dilakukan one-hot encoding\n",
    "            + Setting parameter: `<model>.compile(loss='categorical_crossentropy')` , dengan syarat jumlah node output sama dengan jumlah kelas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Making Architecture\n",
    "\n",
    "Setelah kita mempelajari bagaimana data terlihat, sekarang saatnya untuk mengimplementasikan arsitektur model yang benar.\n",
    "\n",
    "Jika dilihat bentuknya, maka akan terlihat bahwa data kita berbentuk 2 dimensi, oleh karena itu kita akan menambahkan layer `Flatten`. Layer ini digunakan untuk melakukan operasi reshaping pada tensor menjadi array 1 dimensi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed(722)\n",
    "np.random.seed(722)\n",
    "tf.random.set_seed(722)\n",
    "\n",
    "# model initiation\n",
    "model_genre = keras.Sequential(name='model_genre')\n",
    "\n",
    "# input layer\n",
    "model_genre.add(keras.layers.InputLayer(input_shape = (___, ___)))\n",
    "\n",
    "# hidden layer\n",
    "model_genre.add(keras.layers.Flatten(name='flatten_layer'))\n",
    "model_genre.add(keras.layers.Dense(units=___, activation='___', name='hidden_layer_1'))\n",
    "model_genre.add(keras.layers.Dense(units=___, activation='___', name='hidden_layer_2'))\n",
    "model_genre.add(keras.layers.Dense(units=___, activation='___', name='hidden_layer_3'))\n",
    "\n",
    "# outpu layer\n",
    "model_genre.add(keras.layers.Dense(units=___, activation='___', name='output_layer'))\n",
    "\n",
    "# model compile\n",
    "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model_genre.compile(optimizer=optimiser, \n",
    "                    loss='___',\n",
    "                    metrics=['___'])\n",
    "\n",
    "model_genre.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model_genre.fit(X_train, y_train, \n",
    "                                validation_data=(X_test, y_test), \n",
    "                                batch_size=32, \n",
    "                                epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propagation\n",
    "\n",
    "Back Propagation adalah proses mengupdate bobot berdasarkan informasi yang didapatkan dari error hasil prediksi. Informasi yang dicari adalah informasi tentang nilai update yang optimal dengan menggunakan nilai gradient, sehingga metodenya disebut dengan *Gradient Descent*. Untuk mengatur seberapa cepat dan detail model belajar, nilai *Learning Rate* dapat diatur. Semakin kecil learning rate, semakin detail model belajar. Nilai yang biasa digunakan untuk Learning Rate adalah 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contoh tahapan Gradient Descent untuk suatu bobot:\n",
    "\n",
    "- Memplotkan kurva perubahan loss function (error) terhadap bobot\n",
    "- Menghitung gradient (kemiringan/garis singgung) dari bobot awal (yang sedang digunakan) dengan mencari turunan parsialnya (kalkulasi kalkulus)\n",
    "- Mendapatkan nilai gradient dan mengubah bobot berdasarkan rule (lihat gambar):\n",
    "    + nilai positif: bobot perlu dikurangi\n",
    "    + nilai negatif: bobot perlu ditambah\n",
    "![sgd](assets/sgd.gif)\n",
    "\n",
    "Gradient Descent akan membuat model belajar mencari nilai dari masing-masing bobot yang tepat sehingga mendapatkan loss yang semakin kecil. \n",
    "\n",
    "Besar penambahan/penurunan bobot adalah `bobot awal - (gradient x learning rate)`. **Learning rate** adalah seberapa cepat model melakukan update bobot (range: 0 ~ 1):\n",
    "\n",
    "- learning rate rendah:\n",
    "     + membuat model mengupdate bobot sedikit demi sedikit\n",
    "     + waktu untuk mencapai titik lokal optimum dari bobot akan lebih lama\n",
    "     + Namun, jika model sudah menyentuh **local optima** atau titik terendah di antara dua area yang lebih tinggi errornya, model akan sulit untuk lepas dari area tersebut sehingga terdapat kemungkinan juga model tidak bisa mendapatkan **global optima** atau error yang paling rendah.\n",
    "- learning rate tinggi:\n",
    "     + membuat model belajar lebih cepat dengan jumlah step yang lebih sedikit\n",
    "     + kemungkinan besar akan melewatkan titik terendahnya sehingga tidak bisa mencapai nilai error yang optimal.\n",
    "- Pemilihan learning rate adalah salah satu hal yang penting dalam membuat Neural Network.\n",
    "\n",
    "![learning rate](assets/learning_rate.jpg)\n",
    "\n",
    "Apabila tertarik dengan matematika di balik *Gradient Descent*, dapat mengunjungi:\n",
    "- https://ruder.io/optimizing-gradient-descent/\n",
    "- https://jermwatt.github.io/machine_learning_refined/notes/3_First_order_methods/3_6_Descent.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contoh perhitungan update bobot [Optional]**\n",
    "\n",
    "Misalkan kita punya fungsi berikut dari sebuah model:\n",
    "\n",
    "$$\n",
    "f(x) = x^2\n",
    "$$\n",
    "\n",
    "Gradient Descent menggunakan konsep turunan/derivatif untuk mencari nilai error yang optimal. Maka, kita bisa menurunkan fungsi di atas menjadi sebagai berikut:\n",
    "\n",
    "$$\n",
    "f'(x) = 2x\n",
    "$$\n",
    "\n",
    "Untuk mengupdate bobot barunya, kita mengatur seberapa besar perubahan bobotnya menggunakan **learning rate** ($\\alpha$):\n",
    "\n",
    "$$ x\\ baru = x\\ - \\alpha\\ 2 x$$\n",
    "\n",
    "Misal bobot yang sekarang adalah 4 dan learning rate = 0.1\n",
    "\n",
    "$$bobot\\ baru = 4 - 0.1\\times 2\\times 4 = 3.2$$\n",
    "\n",
    "Jika learning rate semakin kecil, perubahan bobotnya juga akan semakin kecil juga, contohnya dengan learning rate = 0.01\n",
    "\n",
    "$$bobot\\ baru = 4 - 0.01\\times 2\\times 4 = 3.92$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Learning and Momentum\n",
    "\n",
    "**Adaptive Learning** merupakan suatu metode untuk mengubah learning rate sesuai kondisi yang terjadi. Skema yang berlaku adalah ketika perubahan gradient descent tidak signifikan maka learning rate ditingkatkan, sementara ketika perubahan gradient descent signifikan maka learning rate dikurangi. Sementara **Momentum** digunakan untuk membantu model keluar dari *local optima* dimana gerakan dari learning rate diberikan energi/momentum agar tidak berhenti. Berikut adalah penggambaran terkait momentum:\n",
    "<img src=\"assets/momentum.gif\" width=\"60%\"> \n",
    "<!-- Source: https://gbhat.com/machine_learning/gradient_descent_nesterov.html -->\n",
    "\n",
    "**Adaptive Moment (Adam)** merupakan optimizers yang menggunakan kedua metode di atas yaitu adaptive learning dan momentum untuk mengatur learning rate dan melakukan update bobot. Berikut adalah [original paper](https://arxiv.org/pdf/1412.6980.pdf) tentang Adam optimizer dan artikel lain tentang Adam juga dapat dibaca pada [link ini](https://mlfromscratch.com/optimizers-explained/#/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "**Learning Rate**\\\n",
    "Learning Rate mempengaruhi seberapa cepat model akan belajar. Tingkat pembelajaran yang besar mungkin menghasilkan waktu yang lebih cepat untuk konvergen tetapi meningkatkan risiko terjebak dalam local optima.\n",
    "\n",
    "**Epoch** \\\n",
    "Epoch yang besar akan memberikan model kesempatan untuk mempelajari data lebih banyak, diharapkan menghasilkan kinerja yang lebih baik dari waktu ke waktu. Namun, model mungkin terkena masalah overfit.\n",
    "\n",
    "### Batch Learning\n",
    "\n",
    "Batch Learning tidak ada hubungannya dengan kinerja model. Namun, hal ini mempengaruhi penggunaan memori untuk setiap model yang kita gunakan.\n",
    "\n",
    "Training menggunakan full batch akan menggunakan seluruh set pelatihan untuk satu update, sementara partial batch learning akan mengevaluasi dan memperbarui untuk setiap batch yang dimilikinya di setiap epoch.\n",
    "\n",
    "Semakin besar ukuran batch, semakin banyak memori yang dibutuhkan untuk melakukan satu siklus pembelajaran (feed forward + backpropagation) tetapi waktu pembelajaran lebih cepat. Disarankan untuk menjaga agar batch tetap rendah untuk mencegah kegagalan model saat memprediksi data.\n",
    "\n",
    "You can set the batch size using `batch_size` parameters on `model.fit()`, for example :\n",
    "\n",
    "```python\n",
    "model.fit(x_train, y_train, epochs=10, batch_size = 30)\n",
    "```\n",
    "\n",
    "**Batch**\n",
    "\n",
    "- Pada proses training, kita bisa membagi data yang ingin di training yang diambil secara *random* sesuai dengan batch\n",
    "- Model akan melakukan training menggunakan data pada batch 1 terlebih dahulu, kemudian batch ke-2, dan seterusnya hingga digunakan semua data --> 1 epoch\n",
    "- Karena model itu dapat ditraining dengan epoch lebih dari 1, yang artinya akan melakukan pembagian batch dengan random yang berbeda dari sebelumnya\n",
    "- Pada setiap step/epoch --> error dan metrics model diupdate\n",
    "\n",
    "**Hal yang perlu diperhatikan**\n",
    "1. Semakin banyak batch (ukuran batch) \n",
    "    - Prosesnya akan semakin lama karena proses optimasi model semakin banyak\n",
    "    - Namun bisa mencegah beban komputasi yang besar di satu waktu sekaligus\n",
    "2. Semakin banyak epoch:\n",
    "    - Erronya semakin kecil\n",
    "    - Prosesnya semakin lama\n",
    "    - Rentan overfit (keadaan dimana nilai train lebih bagus daripada test/validation)\n",
    "    - Biasanya untuk menentukan epoch diawal bisa menggunakan 10/15\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "### Knowledge Check\n",
    "\n",
    "Pertanyaan ini merupakan challenge bagi Bapak/Ibu yang pernah mengikuti course Algoritma tentang metric untuk kasus klasifikasi. Menurut Bapak/Ibu, metric evaluasi apa yang tepat digunakan untuk data yang kita punya, dan kenapa metric tersebut?\n",
    "- [ ] Accuracy\n",
    "- [ ] Precision\n",
    "- [ ] Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada contoh prediksi ini kita tidak akan menggunakan data test yang kita pakai untuk validasi, melainkan menggunakan data baru yang berasal dari folder `genres_test`. Karena menggunakan data baru, kita harus melakukan konversi data dari awal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = \"data_input/genres_test\"\n",
    "# json_path = \"data_test.json\"\n",
    "# sr = 22050 # default sample rate\n",
    "# file_duration = 30 # measured in seconds\n",
    "# samples_per_file = sr * file_duration # total data which need to be converted per file\n",
    "\n",
    "# save_mfcc(dataset_path, json_path, num_segments=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proses evaluasi dari data yang belum kita lihat sebelumnya dapat menggunakan method `.evaluate()` dari model yang telah kita buat. Hasil yang dikeluarkan oleh method ini berupa nilai loss dan akurasi, dan yang akan kita tinjau sebagai metrics yaitu akurasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to json file that stores MFCCs and genre labels for each processed segment\n",
    "# data_predict_path = \"data_input/data_test.json\"\n",
    "data_predict_path = \"data_test.json\"\n",
    "\n",
    "# load data\n",
    "X_pred, y_pred = load_data(data_predict_path)\n",
    "\n",
    "model_genre.evaluate(X_pred, y_pred, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nilai ini bisa coba dibandingkan dengan perhitungan akurasi manual berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# melakukan prediksi dari data di X_pred lalu mengambil nilai dengan peluang paling tinggi\n",
    "prediction = model_genre.predict(X_pred, batch_size=32, verbose=1)\n",
    "prediction = prediction.argmax(axis=1)\n",
    "\n",
    "# membuat dataframe untuk menyimpan data hasil prediksi dan data asli\n",
    "compare = pd.DataFrame({'prediction': prediction, \n",
    "                        'observation': y_pred})\n",
    "\n",
    "# membandingkan nilai dari kedua kolom\n",
    "compare['comparison'] = np.where(compare['prediction'] == compare['observation'], True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengeluarkan perhitungan akurasi dengan menghitung nilai True dari seluruh data\n",
    "manual_accuracy = compare['comparison'].value_counts()[1]/len(prediction)\n",
    "print(\"manual accuracy calculation: \", manual_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Akurasi yang ditampilkan di atas adalah akurasi dari data yang sudah disegmentasi sebagai proses data augmentasi, untuk mengetahui hasil prediksi secara general kita perlu melakukan perhitungan modus dari hasil klasifikasi model. Berikut adalah fungsi untuk mengambil modus dari array kita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def take_mode(result, num_segments=10):\n",
    "    \"\"\"Function to take mode value from num_segments of data\n",
    "        \n",
    "    --Arguments--\n",
    "        result: \n",
    "            Result from model prediction\n",
    "        num_segments:\n",
    "            The segments that we defined when we save and convert data with mfcc\n",
    "    \"\"\"\n",
    "    new_result = []\n",
    "    i = 0\n",
    "    \n",
    "    for i in range(int((len(result)+1)/num_segments)):\n",
    "        new_result.append(Counter(result[(i*num_segments):((i+1)*num_segments)].tolist()).most_common()[0][0])\n",
    "        i += 1\n",
    "        \n",
    "    return new_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y = take_mode(y_pred)\n",
    "new_pred = take_mode(prediction)\n",
    "\n",
    "compare = pd.DataFrame({'prediction': new_pred, \n",
    "                        'observation': new_y})\n",
    "\n",
    "compare['comparison'] = np.where(compare['prediction'] == compare['observation'], True, False)\n",
    "\n",
    "manual_accuracy = compare['comparison'].value_counts()[1]/len(new_pred)\n",
    "manual_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Reusability [Optional]\n",
    "\n",
    "Menyimpan model adalah praktik umum untuk tujuan yang dapat digunakan kembali tetapi sebelum melakukan itu, Anda disarankan untuk memahami apa yang sebenarnya diselamatkan. Dalam keras, model sebenarnya terdiri dari empat komponen:\n",
    "\n",
    "1. The model architecture \n",
    "2. A set of weights values that act as model \"state\",\n",
    "3. An optimizer (defined by compiling the model), and \n",
    "4. A set of losses and metrics (defined by compiling the model or calling add_loss() or add_metric()).\n",
    "\n",
    "Jadi harap diingat bahwa setiap kali kita menyimpan model, informasi tersebut akan disimpan. Keras api memungkinkan kita untuk menyimpan semua komponen atau hanya beberapa dari mereka. Untuk melakukannya, kita dapat menggunakan metode `save()` dari objek model.\n",
    "\n",
    "### Save and load whole model \n",
    "\n",
    "Untuk menyimpan seluruh informasi model, kita dapat menggunakan kode `model.save(path)`. Ada dua cara untuk menyelesaikan kode:\n",
    "1. using `model.save('folder')` will save the model as .pb and each components are separated on different files\n",
    "2. using `model.save('folder/filename.h5')` will save the model as HDF5 file and each components are included within the file\n",
    "\n",
    "sebagai contoh, berikut adalah kode untuk menyimpan model `model_reg` didalam folder `model` \n",
    "```python \n",
    "# Save whole model as archive\n",
    "model.save('folder/model_name')\n",
    "\n",
    "# Save whole model as hdf5 format\n",
    "model.save('folder/model_name.h5')\n",
    "\n",
    "```\n",
    "\n",
    "Untuk menggunakan model yang sudah kita simpan, kita dapat menggunakan method `keras.models.load_model(path)`. Contoh sebagai berikut:\n",
    "\n",
    "```python\n",
    "model_load = keras.models.load_model('folder/model_name')\n",
    "model_load = keras.models.load_model('folder/model_name.h5')\n",
    "```\n",
    "\n",
    "*Note : Gunakan method `model.save()`, menskipun path tidak ada, kode ini akan membuat sebuah directory dan akan melakukan penyimpanan model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_genre.save('model/nn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dive Deeper\n",
    "\n",
    "Cobalah buat model dengan arsitektur Neural Network yang berbeda, lalu coba juga melakukan hyperparameter tuning pada model yang dibuat. Apakah didapatkan hasil yang lebih baik?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation [Optional]\n",
    "\n",
    "Data augmentasi merupakan proses membuat data sample sintetik dengan melakukan tweaking/menambahkan gangguan pada data training. Pada data audio, proses data augmentasi yang dapat dilakukan yaitu noise injection, shifting time, time stretching, and pitch shifting. Selain menambah jumlah dari data training, secara objektif proses ini dilakukan untuk membuat model mempelajari data secara lebih general. Contoh pengaplikasian metode-metode umum data augmentation di atas dapat dilihat pada [medium ini](https://medium.com/@keur.plkar/audio-data-augmentation-in-python-a91600613e47).\n",
    "\n",
    "Pada course ini, kita melakukan data augmentation dengan membuat segmentasi pada data untuk menambah jumlah data kita serta memberikan sample yang lebih bervariasi. Proses ini dapat dilakukan jika data audio kita memiliki waktu yang cukup panjang."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dss_audio2]",
   "language": "python",
   "name": "conda-env-dss_audio2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "262.75px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "5b4b1f0fc864f4ffb2b5befeca87e180e6e3b980f905d779a91cd87569900640"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
